{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import trueskillthroughtime as ttt\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ifsc.results.info data to trueskill\n",
    "takes the data directory and creates trueskill rankings. can be filtered using the selected events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callable functions\n",
    "# TODO add support for speed and lead as well as grp A B qualis\n",
    "def get_boulder(round):\n",
    "    filter = {'athlete_id', 'rank', 'name', 'country'}\n",
    "    filtered_rounds = []\n",
    "    for player in round:\n",
    "        # print(player)\n",
    "        # Create a dictionary for each player with only the desired keys\n",
    "        filtered_player = {k: player[k] for k in filter if k in player}\n",
    "        # Append the filtered dictionary to the list\n",
    "        for player_round in player['rounds']:\n",
    "            match player_round['round_name']:\n",
    "                case 'Qualification' | 'Final' | 'Semi-Final': # maybe fuzzy match qualification a/b options, must test with 2018 years older...\n",
    "                    round_type = player_round['round_name'].replace('-', '').lower()  # Normalize the round name\n",
    "                    if 'speed_elimination_stages' in player_round:\n",
    "                        ascents = player_round['speed_elimination_stages']['ascents'] # grp a/b seems to remove speed elim stage\n",
    "                    else:\n",
    "                        ascents = player_round['ascents']\n",
    "                                        \n",
    "                    \n",
    "                    # Enumerate through ascents and extract required information\n",
    "                    for index, boulder in enumerate(ascents):\n",
    "                        # We will create a consistent data structure for easy access\n",
    "                        boulder_info = {key: boulder[key] for key in ['id', 'top', 'top_tries', 'zone', 'zone_tries','starting_group'] if key in boulder}\n",
    "                        filtered_player[f\"{round_type}_boulder_{index + 1}\"] = boulder_info\n",
    "                    \n",
    "        filtered_rounds.append(filtered_player)\n",
    "    return pd.DataFrame(filtered_rounds)\n",
    "\n",
    "def get_lead(leadRound):\n",
    "    filter = {'athlete_id', 'rank', 'name', 'country'}\n",
    "    lead_filtered_rounds = []\n",
    "\n",
    "    # lead version\n",
    "    for player in leadRound:\n",
    "        # print(player)\n",
    "        # Create a dictionary for each player with only the desired keys\n",
    "        filtered_player = {k: player[k] for k in filter if k in player}\n",
    "        # Append the filtered dictionary to the list\n",
    "        for player_round in player['rounds']:\n",
    "            match player_round['round_name']:\n",
    "                case 'Qualification' | 'Final' | 'Semi-Final': # maybe fuzzy match qualification a/b options, must test with 2018 years older...\n",
    "                    round_type = player_round['round_name'].replace('-', '').lower()  # Normalize the round name\n",
    "                    ascents = player_round['ascents']\n",
    "                    \n",
    "                    # Enumerate through ascents and extract required information\n",
    "                    for index, boulder in enumerate(ascents):\n",
    "                        # We will create a consistent data structure for easy access\n",
    "                        lead_info = {key: boulder[key] for key in ['route_id', 'score', 'top', 'plus', 'rank', 'corrective_rank'] if key in boulder}\n",
    "                        filtered_player[f\"{round_type}_lead_{index + 1}\"] = lead_info\n",
    "        lead_filtered_rounds.append(filtered_player)\n",
    "    return pd.DataFrame(lead_filtered_rounds)\n",
    "\n",
    "\n",
    "def create_composition(frame):\n",
    "    #print(frame.columns)\n",
    "    n_qualis = frame.columns.str.contains('qualification_boulder_').sum()\n",
    "    for i in range(1, n_qualis + 1):\n",
    "        frame[f'q_b_{i}_top'] = frame[f'qualification_boulder_{i}'].apply(lambda x: 1 if isinstance(x, dict) and x['top'] else np.NaN)\n",
    "        frame[f'q_b_{i}_top_tries'] = frame[f'qualification_boulder_{i}'].apply(lambda x: x['top_tries'] if isinstance(x, dict) else np.NaN)\n",
    "        frame[f'q_b_{i}_zone'] = frame[f'qualification_boulder_{i}'].apply(lambda x: 1 if isinstance(x, dict) and x['zone'] else np.NaN)\n",
    "        frame[f'q_b_{i}_zone_tries'] = frame[f'qualification_boulder_{i}'].apply(lambda x: x['zone_tries'] if isinstance(x, dict) else np.NaN)\n",
    "\n",
    "        #per boulder ranking\n",
    "        frame[[f'athlete_id',f'q_b_{i}_top',f'q_b_{i}_top_tries',f'q_b_{i}_zone',f'q_b_{i}_zone_tries']].sort_values([f'q_b_{i}_top',f'q_b_{i}_top_tries',f'q_b_{i}_zone',f'q_b_{i}_zone_tries'],na_position='last')\n",
    "        frame[f'q_b_{i}_rank'] = frame[[f'q_b_{i}_top',f'q_b_{i}_top_tries',f'q_b_{i}_zone',f'q_b_{i}_zone_tries']].apply(tuple,axis=1).rank(method='dense',ascending=True) # i still dont understand why this works \n",
    "    \n",
    "    n_finals = sum('finals' in col for col in frame.columns) # \n",
    "    for i in range(1, n_finals + 1):\n",
    "        frame[f'f_b_{i}_top'] = frame[f'final_boulder_{i}'].apply(lambda x: 1 if isinstance(x, dict) and x['top'] else np.NaN)\n",
    "        frame[f'f_b_{i}_top_tries'] = frame[f'final_boulder_{i}'].apply(lambda x: x['top_tries'] if isinstance(x, dict) else np.NaN)\n",
    "        frame[f'f_b_{i}_zone'] = frame[f'final_boulder_{i}'].apply(lambda x: 1 if isinstance(x, dict) and x['zone'] else np.NaN)\n",
    "        frame[f'f_b_{i}_zone_tries'] = frame[f'final_boulder_{i}'].apply(lambda x: x['zone_tries'] if isinstance(x, dict) else np.NaN)\n",
    "        \n",
    "        frame[[f'athlete_id',f'f_b_{i}_top',f'f_b_{i}_top_tries',f'f_b_{i}_zone',f'f_b_{i}_zone_tries']].sort_values([f'f_b_{i}_top',f'f_b_{i}_top_tries',f'f_b_{i}_zone',f'f_b_{i}_zone_tries'],na_position='last')\n",
    "        frame[f'f_b_{i}_rank'] = frame[[f'f_b_{i}_top',f'f_b_{i}_top_tries',f'f_b_{i}_zone',f'f_b_{i}_zone_tries']].apply(tuple,axis=1).rank(method='dense',ascending=True)\n",
    "        \n",
    "        \n",
    "    n_semis = frame.columns.str.contains('semifinal_boulder_').sum()\n",
    "    for i in range(1, n_semis + 1):\n",
    "        frame[f's_b_{i}_top'] = frame[f'semifinal_boulder_{i}'].apply(lambda x: 1 if isinstance(x, dict) and x['top'] else np.NaN)\n",
    "        frame[f's_b_{i}_top_tries'] = frame[f'semifinal_boulder_{i}'].apply(lambda x: x['top_tries'] if isinstance(x, dict) else np.NaN)\n",
    "        frame[f's_b_{i}_zone'] = frame[f'semifinal_boulder_{i}'].apply(lambda x: 1 if isinstance(x, dict) and x['zone'] else np.NaN)\n",
    "        frame[f's_b_{i}_zone_tries'] = frame[f'semifinal_boulder_{i}'].apply(lambda x: x['zone_tries'] if isinstance(x, dict) else np.NaN)\n",
    "        \n",
    "        frame[[f'athlete_id',f's_b_{i}_top',f's_b_{i}_top_tries',f's_b_{i}_zone',f's_b_{i}_zone_tries']].sort_values([f's_b_{i}_top',f's_b_{i}_top_tries',f's_b_{i}_zone',f's_b_{i}_zone_tries'],na_position='last')\n",
    "        frame[f's_b_{i}_rank'] = frame[[f's_b_{i}_top',f's_b_{i}_top_tries',f's_b_{i}_zone',f's_b_{i}_zone_tries']].apply(tuple,axis=1).rank(method='dense',ascending=True)\n",
    "    \n",
    "    # create a composition for each boulder, with athlete_id as a player\n",
    "\n",
    "    # frame['boulder_1_ranks'] = frame['boulder_1'].apply(lambda x: x.split(' ')[0]\n",
    "    return frame#[['athlete_id','rank','name','qualification_boulder_1','boulder_1_top','boulder_1_top_tries','boulder_1_zone','boulder_1_zone_tries']]\n",
    "\n",
    "# create_composition(get_boulder(round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 processed events and 8 errored events\n",
      "Iteration =  0 , step =  (10.433630266086908, 2.9130396399537704)\n",
      "Iteration =  1 , step =  (0.44897565254086125, 0.1605280789624428)\n",
      "Iteration =  2 , step =  (0.08555472489639238, 0.015946887523178077)\n",
      "Iteration =  3 , step =  (0.04530834956818275, 0.003365253523368583)\n",
      "Iteration =  4 , step =  (0.03077419429991568, 0.0024312397205230596)\n",
      "Iteration =  5 , step =  (0.024012605467288894, 0.001983219924457824)\n",
      "Iteration =  6 , step =  (0.0205665140574105, 0.0020004376200692953)\n",
      "Iteration =  7 , step =  (0.018723464149536073, 0.002163540817472054)\n",
      "Iteration =  8 , step =  (0.017839117904512314, 0.002219761295821243)\n",
      "Iteration =  9 , step =  (0.017291433416398494, 0.002224799079634465)\n",
      "Iteration =  10 , step =  (0.016967730966948036, 0.002205511944788352)\n",
      "Iteration =  11 , step =  (0.016646544553608145, 0.002174861088980684)\n",
      "Iteration =  12 , step =  (0.016324967713015948, 0.0021391017813083835)\n",
      "Iteration =  13 , step =  (0.01600648221205203, 0.0021012505911772728)\n",
      "Iteration =  14 , step =  (0.015692704326412787, 0.002062759328328667)\n",
      "Iteration =  15 , step =  (0.015384351100509175, 0.002024323696554031)\n",
      "Iteration =  16 , step =  (0.01508170666395392, 0.0019862740495795173)\n",
      "Iteration =  17 , step =  (0.014784847338526141, 0.0019487642333650967)\n",
      "Iteration =  18 , step =  (0.014493750304272357, 0.0019118628528587145)\n",
      "Iteration =  19 , step =  (0.014208346045696096, 0.0018755973816215743)\n",
      "Iteration =  20 , step =  (0.013928543652916403, 0.001839975480292022)\n",
      "Iteration =  21 , step =  (0.013654243015815304, 0.0018049953001320063)\n",
      "Iteration =  22 , step =  (0.013385340689908709, 0.0017706504630150555)\n",
      "Iteration =  23 , step =  (0.013121732706881328, 0.0017369324685385656)\n",
      "Iteration =  24 , step =  (0.012863315910324857, 0.0017038318576783062)\n",
      "Iteration =  25 , step =  (0.012609988579666442, 0.0016713387753601872)\n",
      "Iteration =  26 , step =  (0.012361650710841943, 0.0016394432425941297)\n",
      "Iteration =  27 , step =  (0.012118204131706278, 0.0016081352881140987)\n",
      "Iteration =  28 , step =  (0.011879552537911398, 0.0015774050120440641)\n",
      "Iteration =  29 , step =  (0.011645601490843482, 0.0015472426167821851)\n",
      "End\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>current</th>\n",
       "      <th>sigma</th>\n",
       "      <th>mu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Adam</td>\n",
       "      <td>ONDRA</td>\n",
       "      <td>N(mu=4.226, sigma=0.221)</td>\n",
       "      <td>0.220824</td>\n",
       "      <td>4.226338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13040</th>\n",
       "      <td>Sorato</td>\n",
       "      <td>ANRAKU</td>\n",
       "      <td>N(mu=4.159, sigma=0.408)</td>\n",
       "      <td>0.407977</td>\n",
       "      <td>4.158589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>Kilian</td>\n",
       "      <td>FISCHHUBER</td>\n",
       "      <td>N(mu=4.123, sigma=0.194)</td>\n",
       "      <td>0.193825</td>\n",
       "      <td>4.123029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>Tomoa</td>\n",
       "      <td>NARASAKI</td>\n",
       "      <td>N(mu=4.040, sigma=0.188)</td>\n",
       "      <td>0.187828</td>\n",
       "      <td>4.040242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11675</th>\n",
       "      <td>Mejdi</td>\n",
       "      <td>SCHALCK</td>\n",
       "      <td>N(mu=3.929, sigma=0.294)</td>\n",
       "      <td>0.294103</td>\n",
       "      <td>3.929157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>Abdulla</td>\n",
       "      <td>ALDOSERI</td>\n",
       "      <td>N(mu=-8.187, sigma=3.003)</td>\n",
       "      <td>3.002784</td>\n",
       "      <td>-8.187233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>Mario</td>\n",
       "      <td>LACKNER</td>\n",
       "      <td>N(mu=-8.634, sigma=3.291)</td>\n",
       "      <td>3.290856</td>\n",
       "      <td>-8.634462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>Mandeep</td>\n",
       "      <td>KODAN</td>\n",
       "      <td>N(mu=-9.873, sigma=3.093)</td>\n",
       "      <td>3.093044</td>\n",
       "      <td>-9.872740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7410</th>\n",
       "      <td>Artem</td>\n",
       "      <td>AVDEENKO</td>\n",
       "      <td>N(mu=-10.145, sigma=3.206)</td>\n",
       "      <td>3.205880</td>\n",
       "      <td>-10.145233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>Yuhang</td>\n",
       "      <td>ZHANG</td>\n",
       "      <td>N(mu=-10.889, sigma=3.086)</td>\n",
       "      <td>3.085943</td>\n",
       "      <td>-10.888745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1308 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      firstname    lastname                     current     sigma         mu\n",
       "1364       Adam       ONDRA    N(mu=4.226, sigma=0.221)  0.220824   4.226338\n",
       "13040    Sorato      ANRAKU    N(mu=4.159, sigma=0.408)  0.407977   4.158589\n",
       "1204     Kilian  FISCHHUBER    N(mu=4.123, sigma=0.194)  0.193825   4.123029\n",
       "2276      Tomoa    NARASAKI    N(mu=4.040, sigma=0.188)  0.187828   4.040242\n",
       "11675     Mejdi     SCHALCK    N(mu=3.929, sigma=0.294)  0.294103   3.929157\n",
       "...         ...         ...                         ...       ...        ...\n",
       "4444    Abdulla    ALDOSERI   N(mu=-8.187, sigma=3.003)  3.002784  -8.187233\n",
       "5860      Mario     LACKNER   N(mu=-8.634, sigma=3.291)  3.290856  -8.634462\n",
       "2650    Mandeep       KODAN   N(mu=-9.873, sigma=3.093)  3.093044  -9.872740\n",
       "7410      Artem    AVDEENKO  N(mu=-10.145, sigma=3.206)  3.205880 -10.145233\n",
       "4990     Yuhang       ZHANG  N(mu=-10.889, sigma=3.086)  3.085943 -10.888745\n",
       "\n",
       "[1308 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#main process\n",
    "\n",
    "data_folder = '../data'\n",
    "\n",
    "output_folder = os.path.join(data_folder, 'output')\n",
    "output_events_folder = os.path.join(data_folder, 'outputEvents')\n",
    "full_results_folder = os.path.join(data_folder, 'outputFullResults')\n",
    "athlete_folder = os.path.join(data_folder, 'athlete')\n",
    "\n",
    "output_data = []\n",
    "output_events_data = []\n",
    "full_results_data = []\n",
    "athlete_data = []\n",
    "\n",
    "# Load data from output folder\n",
    "for filename in os.listdir(output_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(output_folder, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            output_data.append(data)\n",
    "\n",
    "# Load data from outputEvents folder\n",
    "for filename in os.listdir(output_events_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(output_events_folder, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            output_events_data.append(data)\n",
    "\n",
    "# Load data from FullResults folder\n",
    "for filename in os.listdir(full_results_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(full_results_folder, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            data['filename'] = filename\n",
    "            full_results_data.append(data)\n",
    "\n",
    "for filename in os.listdir(athlete_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(athlete_folder, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            athlete_data.append(data)\n",
    "# Load data from athlete folder \n",
    "\n",
    "\n",
    "allEvents = pd.DataFrame(full_results_data)\n",
    "allEvents['ranking'].dropna(inplace=True)\n",
    "allEvents['ranking_as_of'].dropna(inplace=True)\n",
    "allEvents['date'] = pd.to_datetime(allEvents['ranking_as_of'] , errors='coerce')\n",
    "\n",
    "athletes = pd.DataFrame(athlete_data)\n",
    "athletes = athletes[['id', 'firstname', 'lastname', 'birthday', 'gender', 'country', 'all_results']]\n",
    "athletes['all_results']\n",
    "def split_filename(name):\n",
    "    return int(name.split('_')[1])\n",
    "\n",
    "allEvents['id'] = allEvents['filename'].apply(split_filename)\n",
    "allEvents['cid'] = allEvents['filename'].apply(lambda x: x.split('_')[2][:-5]) # selects the last number split by _ and removes the .json (5 char)\n",
    "allEvents.set_index('id', inplace=True)\n",
    "events = pd.DataFrame(output_events_data)\n",
    "events.set_index('id', inplace=True)\n",
    "\n",
    "joined_df = allEvents.join(events)\n",
    "joined_df.dropna(subset=['ranking'], inplace=True)\n",
    "\n",
    "joined_df[joined_df.ranking.notna()][['event', 'starts_at', 'dcat', 'ranking', 'location','cid', 'league_id', 'league_season_id', 'season_id']].sort_values('starts_at')\n",
    "\n",
    "selected_events = joined_df[\n",
    "    (joined_df['league_id'] == 1) & (\n",
    "        # (joined_df['dcat'] == 'LEAD Men') | \n",
    "        # (joined_df['dcat'] == 'LEAD Women') | \n",
    "        (joined_df['dcat'] == 'BOULDER Men')  \n",
    "        # | (joined_df['dcat'] == 'BOULDER Women')\n",
    "    ) &\n",
    "    (joined_df['starts_at'] > '2007-01-01') & # 2007 is the first year of the IFSC - pre 2007 per boulder rankings dont exist\n",
    "    (joined_df['starts_at'] < '2024-01-01')\n",
    "][['event', 'starts_at', 'dcat','cid', 'ranking', 'location', 'league_id', 'league_season_id', 'season_id']].sort_values('starts_at')\n",
    "selected_events\n",
    "\n",
    "processed_events = []\n",
    "errored_events = []\n",
    "for event in selected_events.itertuples(index=True):\n",
    "    # print(event.Index)\n",
    "    try:\n",
    "        c = create_composition(get_boulder(event.ranking))\n",
    "        processed_events.append({'event_id': event.Index,'cid':event.cid,'event_name':event.event, 'starts_at':event.starts_at,'dataframe': c}) # dict of eventID and then the comp df\n",
    "        \n",
    "    except:\n",
    "        errored_events.append(event)\n",
    "        # print(event)\n",
    "    # print(event.ranking[0])\n",
    "   \n",
    "print(f\"{len(processed_events)} processed events and {len(errored_events)} errored events\")     \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "temp = pd.DataFrame(processed_events)\n",
    "test_comp_final_results = []\n",
    "for row in temp.itertuples():\n",
    "    test_comp_final_results.append(row.dataframe.athlete_id.apply(lambda x: [x]).to_list())\n",
    "\n",
    "h = ttt.History(composition=test_comp_final_results)\n",
    "h.convergence()\n",
    "lc = pd.DataFrame.from_dict(h.learning_curves(),orient='index')\n",
    "lc['current'] = lc.apply(lambda x: x[x.last_valid_index()][1],axis=1)\n",
    "lc['sigma'] = lc['current'].apply(lambda x: x.sigma)\n",
    "lc['mu'] = lc['current'].apply(lambda x: x.mu)\n",
    "lc[['current', 'sigma', 'mu']].sort_values(by=['mu'],ascending=False).head(20)\n",
    "lc.join(athletes.set_index('id'))[['firstname','lastname','current', 'sigma', 'mu']].sort_values(by=['mu'],ascending=False)#.to_csv('output_men.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv?\n",
    "lc.join(athletes.set_index('id'))[['firstname','lastname','current', 'sigma', 'mu']].sort_values(by=['mu'],ascending=False)#.to_csv('output_men.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select boulder and lead events, extract r0ound data into objects tagged with event info like id, cid, name, date. essential. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
